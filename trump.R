library(tm)
library(wordcloud)
setwd("C:/Users/prosh/Documents/R/texttrump")
source<-DirSource("C:/Users/prosh/Documents/R/texttrump")
YourCorpus <- Corpus(source, readerControl=list(reader=readPlain))
dtm <- DocumentTermMatrix(YourCorpus)
inspect(dtm)
wordcloud(YourCorpus, min.freq=25, color=brewer.pal(6, "Dark2") )
library(lda)
doclines <- lexicalize(YourCorpus)
result <- lda.collapsed.gibbs.sampler(doclines$documents, 10, doclines$vocab,250, 0.1, 0.1, compute.log.likelihood = TRUE)
cloud.data <- sort(result$topics[1, ], decreasing = TRUE)[1:50]
wordcloud(names(cloud.data), freq = cloud.data, scale = c(4, 0.1), min.freq = 1,rot.per = 0, random.order = FALSE,colors=brewer.pal(5,"Set1"))
library(igraph)
tdm = as.matrix(dtm)
termMatrix <- tdm %*% t(tdm)
g <- graph.adjacency(termMatrix, weighted=T, mode = "undirected")
plot(g)
myStopwords <- c("and","the","that","their","this","where","with","when","they")
myCorpus <- tm_map(YourCorpus, removeWords, myStopwords)
wordcloud(myCorpus, colors=brewer.pal(5,"Set1"),random.order=FALSE,max.words=50)
corp <- tm_map(YourCorpus, removePunctuation)
corp <- tm_map(corp, removeNumbers)
corp <- tm_map(corp, removeWords, stopwords("english"))
corp <- tm_map(corp, stripWhitespace)
library(SnowballC)
corp <- tm_map(corp, stemDocument)
corp <- tm_map(corp, content_transformer(tolower))
myStopwords <- c("and","the","that","have","this","you","it's","your","said","where","with","has","you","when","they","was","what","dont","its")
myCorpus <- tm_map(corp, removeWords, myStopwords)
wordcloud(myCorpus, colors=brewer.pal(5,"Set1"),random.order=FALSE,max.words=50)